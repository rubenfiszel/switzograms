{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import jsonpickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_tiles = pd.read_csv('../qgis/hexagons_centers.csv').shape[0]\n",
    "print(\"# of tiles: \", n_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops_with_ids = pd.read_csv(\"../qgis/stops_with_tile_ids.csv\", usecols = ['ID','stop_id'])\n",
    "stops_with_ids = stops_with_ids.set_index('stop_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing centers of hexagons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('../graph/complete.graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops_with_ids['degree'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hexagons where no affluence data is available from official **SBB/CFF** sources, we use the max node-degree in the cell as affluence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = G.nodes()\n",
    "\n",
    "errors = 0\n",
    "for n in nodes:\n",
    "    try:\n",
    "        stops_with_ids.loc[n].degree = G.degree(n) \n",
    "    except KeyError:\n",
    "        errors += 1\n",
    "        \n",
    "print(\"Nodes missing in graph: {}/{}, when matched with `stops_with_ids`\".format(errors, len(nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby the hexagon ID and aggregate by max affluence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_by_degree = stops_with_ids.reset_index().groupby('ID')['stop_id', 'degree'].agg({'degree': max})\n",
    "grouped_by_degree.columns = grouped_by_degree.columns.droplevel()\n",
    "grouped_by_degree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = grouped_by_degree[grouped_by_degree.degree == 0].shape[0]\n",
    "total = grouped_by_degree.shape[0]\n",
    "print(\"After grouping, missing degree data for {}/{} cells\".format(missing, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affluence for available nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affluence = pd.read_csv(\"passagierfrequenz.csv\", sep=';')\n",
    "affluence['x'], affluence['y'] = affluence.geopos.str.split(',', 1).str\n",
    "affluence = affluence.drop(['Bahnhof_Haltestelle', 'DWV', 'Bemerkungen', 'lod', 'geopos', 'Eigner', 'Bezugsjahr'], axis=1)\n",
    "affluence.columns = ['Code', 'Affluence', 'x', 'y']\n",
    "affluence['stop_id'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affluence_with_ids = pd.read_csv(\"../qgis/affluence_with_tile_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_aff = affluence.join(affluence_with_ids, rsuffix='_r').drop(\n",
    "        ['x', 'y', 'Code_r', 'stop_id', 'Code'], axis=1)\n",
    "grouped_by_affluence = joined_aff.groupby('ID').agg(max).reset_index()\n",
    "\n",
    "print(\"Centers with affluence data: {}\".format(grouped_by_affluence.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affluence = affluence.join(affluence_with_ids, rsuffix='_r').drop(['Code_r'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = pd.read_csv('../gtfs/stops.txt').drop(['Unnamed: 0', 'platform_code'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get closest stop match by euclidean distance between coordinates -> heuristic \n",
    "Result stored in `gtfs/affluence_with_stopid.csv`\n",
    "\n",
    "**WARNING**: takes some time to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_SIZE = sys.maxsize\n",
    "for i in range(affluence.shape[0]):\n",
    "    min_ = MAX_SIZE\n",
    "    min_id = None\n",
    "    x1 = float(affluence.loc[i].x)\n",
    "    y1 = float(affluence.loc[i].y)\n",
    "    for j in range(stops.shape[0]):\n",
    "        x2 = float(stops.loc[j].stop_lat)\n",
    "        y2 = float(stops.loc[j].stop_lon)\n",
    "        dist = math.sqrt(pow(abs(x1-x2),2) + pow(abs(y1 - y2),2))\n",
    "        if dist < min_:\n",
    "            min_ = dist\n",
    "            min_id = stops.loc[j].stop_id\n",
    "    affluence.set_value(i, 'stop_id', min_id)\n",
    "    if (i%25 == 0):\n",
    "        print(\"{}/{}\".format(i, affluence.shape[0]))\n",
    "        \n",
    "affluence.to_csv('affluence_with_stopid.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instead** use pre-computed file below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affluence = pd.read_csv('affluence_with_stopid.csv')\n",
    "affluence.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge max affluence nodes for each cell with corresponding stop_id (gtfs format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affluence_stop_ids = grouped_by_affluence.merge(affluence, left_on=['ID', 'Affluence'],\n",
    "                          right_on=['ID', 'Affluence'])[['ID', 'stop_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the results from affluence and degree to one collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell_centers = grouped_by_degree.drop(['degree'], axis=1)\n",
    "for i in range(affluence_stop_ids.shape[0]):\n",
    "    cell_id = affluence_stop_ids.loc[i].ID\n",
    "    stop_id = affluence_stop_ids.loc[i].stop_id\n",
    "    cell_centers.set_value(cell_id, 'stop_id', stop_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of all centers\n",
    "\n",
    "## IMPORTANT: sort the centers by tile-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell_centers = cell_centers.reindex(range(1, n_tiles+1), fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst_centers = list(map(lambda x: int(x), cell_centers.stop_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes = G.nodes()\n",
    "filt_centers = []\n",
    "for c in lst_centers:\n",
    "    if c in nodes:\n",
    "        filt_centers.append(c)\n",
    "    else: \n",
    "        filt_centers.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../res/center_nodes', 'wb') as f:\n",
    "    pickle.dump(filt_centers, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
